import torch.nn as nn
import torch
import torch.nn.functional as F
from typing import Optional

class XnetFeedForward(nn.Module):
    def __init__(
        self,
        dim: int,
        hidden_dim: int,
        multiple_of: int,
        ffn_dim_multiplier: Optional[float],
        mp_size: int = 1,
    ):
        super().__init__()

        if ffn_dim_multiplier is not None:
            hidden_dim = int(ffn_dim_multiplier * hidden_dim)
        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)
        assert hidden_dim % mp_size == 0

        self.dim = dim
        self.hidden_dim = hidden_dim

        self.w1 = nn.Linear(
            dim,
            hidden_dim,
            bias=False,
        )
        self.d = nn.Parameter(
            torch.Tensor(hidden_dim)
        )
        self.lambda1 = nn.Parameter(
            torch.Tensor(hidden_dim)
        )
        self.lambda2 = nn.Parameter(
            torch.Tensor(hidden_dim)
        )
        self.w2 = nn.Linear(
            hidden_dim,
            dim,
            bias=False,
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # B S D
        x1 = self.w1(x.view_as(x))
        denom = torch.pow(x1, 2) + torch.pow(self.d, 2)        
        output = self.w2(self.lambda1 * x1 / denom + self.lambda2 / denom)
        return output

    def reset_parameters(self, init_std=None, factor=1.0):
        in_init_std = init_std or (self.dim ** (-0.5))
        out_init_std = init_std or (self.hidden_dim ** (-0.5))
        in_init_std = in_init_std / factor
        out_init_std = out_init_std / factor
        for w in [self.w1, self.w2]:
            nn.init.trunc_normal_(
                w.weight,
                mean=0.0,
                std=in_init_std,
                a=-3 * in_init_std,
                b=3 * in_init_std,
            )
        for w in [self.d, self.lambda1, self.lambda2]:
            nn.init.trunc_normal_(
                w,
                mean=0.0,
                std=out_init_std,
                a=-3 * out_init_std,
                b=3 * out_init_std,
            )
        nn.init.trunc_normal_(
            self.w2.weight,
            mean=0.0,
            std=out_init_std,
            a=-3 * out_init_std,
            b=3 * out_init_std,
        )